{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model_utils import load_base_models\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# 加载模型\n",
    "_, _, seg = load_base_models()\n",
    "\n",
    "# 图像转换\n",
    "color_image_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# 定义图像文件夹路径和输出文件夹路径\n",
    "input_folder = 'test_images/loukonghair/'\n",
    "output_folder = 'output_masks/bisenet/'\n",
    "\n",
    "# 确保输出文件夹存在\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 遍历图像文件夹\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".png\") or filename.endswith(\".jpg\"):\n",
    "        # 读取图像\n",
    "        color_ref_img = Image.open(os.path.join(input_folder, filename))\n",
    "\n",
    "        # 图像转换\n",
    "        color_cond = color_image_transform(color_ref_img).unsqueeze(0).cuda()\n",
    "\n",
    "        # 获取分割结果\n",
    "        if color_cond.shape[-1] != 1:\n",
    "            labels_predict = torch.argmax(seg(color_cond)[0], dim=1).unsqueeze(1).long().detach()\n",
    "            face_classes = torch.tensor([10], device=labels_predict.device)\n",
    "            face_mask = torch.isin(labels_predict, face_classes).float().cuda()\n",
    "\n",
    "            # 将非蒙版部分设为0\n",
    "            color_cond[0] *= face_mask[0]\n",
    "\n",
    "            denormalize = transforms.Normalize(mean=[-1, -1, -1], std=[2, 2, 2])\n",
    "            color_cond_denormalized = denormalize(color_cond[0]).clamp(0, 1)\n",
    "\n",
    "            # 生成输出文件路径\n",
    "            output_path = os.path.join(output_folder, filename.replace(\".\", \"_segmented.\"))\n",
    "            \n",
    "            # 保存分割结果\n",
    "            pil_image = transforms.ToPILImage()(color_cond_denormalized.cpu())\n",
    "            pil_image.save(output_path)\n",
    "\n",
    "print(\"Segmentation and saving complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from modelscope.outputs import OutputKeys\n",
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "\n",
    "inference = pipeline(\"face_recognition\", model='bubbliiiing/cv_retinafce_recognition', model_revision='v1.0.3')\n",
    "\n",
    "img1 = 'test_images/ref_img/000.jpg'\n",
    "img2 = 'test_images/src_img/5.png'\n",
    "emb1 = inference(dict(user=img1))[OutputKeys.IMG_EMBEDDING]\n",
    "emb2 = inference(dict(user=img2))[OutputKeys.IMG_EMBEDDING]\n",
    "sim = np.dot(emb1[0], emb2[0])\n",
    "print(f'Face cosine similarity={sim:.3f}, img1:{img1}  img2:{img2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 指定文件夹路径\n",
    "folder_path = 'test_images/celeba_hq256_100_w'\n",
    "\n",
    "# 初始化计数器\n",
    "i = 0\n",
    "\n",
    "# 遍历文件夹中的文件\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.jpg'):\n",
    "        # 提取文件名和扩展名\n",
    "        name, ext = os.path.splitext(filename)\n",
    "        \n",
    "        # 格式化新的文件名，使用zfill(5)确保数字部分总长度为5，并在前面用0填充\n",
    "        new_name = f\"{i:05d}{ext}\"\n",
    "        \n",
    "        # 构建旧路径和新路径\n",
    "        old_path = os.path.join(folder_path, filename)\n",
    "        new_path = os.path.join(folder_path, new_name)\n",
    "        \n",
    "        # 重命名文件\n",
    "        os.rename(old_path, new_path)\n",
    "        \n",
    "        # 计数器递增\n",
    "        i += 1\n",
    "\n",
    "print(\"重命名完成！\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e4e和原图的余弦相似度均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from modelscope.outputs import OutputKeys\n",
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "from tqdm import tqdm  # 导入tqdm\n",
    "\n",
    "def calculate_cosine_similarity(img_path1, img_path2):\n",
    "    inference = pipeline(\"face_recognition\", model='bubbliiiing/cv_retinafce_recognition', model_revision='v1.0.3')\n",
    "    \n",
    "    emb1 = inference(dict(user=img_path1))[OutputKeys.IMG_EMBEDDING]\n",
    "    emb2 = inference(dict(user=img_path2))[OutputKeys.IMG_EMBEDDING]\n",
    "    sim = np.dot(emb1[0], emb2[0])\n",
    "    \n",
    "    return sim\n",
    "\n",
    "def calculate_mean_cosine_similarity(directory1, directory2):\n",
    "     # 获取目录中的所有文件，并按照数字顺序排序\n",
    "    files1 = sorted(os.listdir(directory1))\n",
    "    files2 = sorted(os.listdir(directory2))\n",
    "    \n",
    "    # 确保两个目录中的文件数量相同\n",
    "    # assert len(files1) == len(files2), \"目录中的文件数量不一致\"\n",
    "    \n",
    "    # 存储每对图片的余弦相似度\n",
    "    similarities = []\n",
    "    \n",
    "    # 遍历每一对图片，使用tqdm创建一个进度条\n",
    "    for file1, file2 in tqdm(zip(files1, files2), total=len(files1), desc=\"计算相似度\"):\n",
    "        img_path1 = os.path.join(directory1, file1)\n",
    "        img_path2 = os.path.join(directory2, file2)\n",
    "        \n",
    "        # 计算余弦相似度\n",
    "        similarity = calculate_cosine_similarity(img_path1, img_path2)\n",
    "        print(similarity)\n",
    "        similarities.append(similarity)\n",
    "    \n",
    "    # 计算均值\n",
    "    mean_similarity = np.mean(similarities)\n",
    "    \n",
    "    return mean_similarity\n",
    "\n",
    "# 两个目录的路径\n",
    "path1 = 'test_images/partbarbershop/'\n",
    "path2 = 'test_images/celeba_hq256_100/'\n",
    "#path2 = 'test_images/celeba_hq256_100_w/'\n",
    "\n",
    "# 计算余弦相似度的均值\n",
    "mean_similarity = calculate_mean_cosine_similarity(path1, path2)\n",
    "\n",
    "print(f\"均值余弦相似度: {mean_similarity:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算SSIM和PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "import numpy as np\n",
    "\n",
    "def calculate_metrics(image1_path, image2_path):\n",
    "    # Read images\n",
    "    img1 = cv2.imread(image1_path)\n",
    "    img2 = cv2.imread(image2_path)\n",
    "\n",
    "    # Convert images to grayscale if needed\n",
    "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate SSIM\n",
    "    ssim_value, _ = ssim(img1_gray, img2_gray, full=True)\n",
    "\n",
    "    # Calculate PSNR\n",
    "    psnr_value = psnr(img1, img2)\n",
    "\n",
    "    return ssim_value, psnr_value\n",
    "\n",
    "def calculate_mean_metrics(folder1, folder2):\n",
    "    ssim_values = []\n",
    "    psnr_values = []\n",
    "\n",
    "    for filename1, filename2 in tqdm(zip(folder1, folder2), total=len(folder1), desc=\"计算相似度\"):\n",
    "        if filename1.endswith('.jpg') or filename1.endswith('.png'):\n",
    "            image1_path = os.path.join(folder1, filename1)\n",
    "        if filename2.endswith('.jpg') or filename1.endswith('.png'):\n",
    "            image2_path = os.path.join(folder2, filename)         \n",
    "\n",
    "        if os.path.exists(image1_path):\n",
    "            ssim_value, psnr_value = calculate_metrics(image1_path, image2_path)\n",
    "            ssim_values.append(ssim_value)\n",
    "            psnr_values.append(psnr_value)\n",
    "\n",
    "    mean_ssim = np.mean(ssim_values)\n",
    "    mean_psnr = np.mean(psnr_values)\n",
    "\n",
    "    return mean_ssim, mean_psnr\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder1_path = \"test_images/partbarbershop/\"\n",
    "    folder2_path = \"test_images/celeba_hq256_100/\"\n",
    "\n",
    "    mean_ssim, mean_psnr = calculate_mean_metrics(folder1_path, folder2_path)\n",
    "\n",
    "    print(f\"Mean SSIM: {mean_ssim:.4f}\")\n",
    "    print(f\"Mean PSNR: {mean_psnr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "import numpy as np\n",
    "\n",
    "def calculate_metrics(image1_path, image2_path):\n",
    "    # Read images\n",
    "    img1 = cv2.imread(image1_path)\n",
    "    img2 = cv2.imread(image2_path)\n",
    "\n",
    "    # Convert images to grayscale if needed\n",
    "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate SSIM\n",
    "    ssim_value, _ = ssim(img1_gray, img2_gray, full=True)\n",
    "\n",
    "    # Calculate PSNR\n",
    "    psnr_value = psnr(img1, img2)\n",
    "\n",
    "    return ssim_value, psnr_value\n",
    "\n",
    "def calculate_mean_metrics(folder1, folder2):\n",
    "    ssim_values = []\n",
    "    psnr_values = []\n",
    "\n",
    "    # Get a list of sorted filenames\n",
    "    filenames1 = sorted(os.listdir(folder1))\n",
    "    filenames2 = sorted(os.listdir(folder2))\n",
    "\n",
    "    for filename1, filename2 in zip(filenames1, filenames2):\n",
    "        if (filename1.endswith('.jpg') or filename1.endswith('.png')) and (filename2.endswith('.jpg') or filename2.endswith('.png')):\n",
    "            image1_path = os.path.join(folder1, filename1)\n",
    "            image2_path = os.path.join(folder2, filename2)\n",
    "\n",
    "            ssim_value, psnr_value = calculate_metrics(image1_path, image2_path)\n",
    "            ssim_values.append(ssim_value)\n",
    "            psnr_values.append(psnr_value)\n",
    "\n",
    "    mean_ssim = np.mean(ssim_values)\n",
    "    mean_psnr = np.mean(psnr_values)\n",
    "\n",
    "    return mean_ssim, mean_psnr\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder1_path = \"output_masks/cross1/\"\n",
    "    folder2_path = \"output_masks/cross2/\"\n",
    "\n",
    "    mean_ssim, mean_psnr = calculate_mean_metrics(folder1_path, folder2_path)\n",
    "\n",
    "    print(f\"Mean SSIM: {mean_ssim:.4f}\")\n",
    "    print(f\"Mean PSNR: {mean_psnr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获得图片除了头发蒙版外相交区域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model_utils import load_base_models\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "# 加载模型\n",
    "_, _, seg = load_base_models()\n",
    "\n",
    "path1 = 'test_images/celeba_hq256_100'\n",
    "path2 = 'test_images/partbarbershop'\n",
    "files1 = sorted(os.listdir(path1))\n",
    "files2 = sorted(os.listdir(path2))\n",
    "\n",
    "# 图像转换\n",
    "color_image_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "i=0\n",
    "for  img1_path,img2_path in tqdm(zip(files1,files2)):\n",
    "    img1 = Image.open(f'{path1}/{img1_path}')\n",
    "    img2 = Image.open(f'{path2}/{img2_path}')\n",
    "    img1 = color_image_transform(img1).unsqueeze(0).cuda()\n",
    "    img2 = color_image_transform(img2).unsqueeze(0).cuda()\n",
    "\n",
    "    if img1.shape[-1] != 1 & img2.shape[-1] != 1:\n",
    "       \n",
    "        labels_predict1 = torch.argmax(seg(img1)[0], dim=1).unsqueeze(1).long().detach()\n",
    "        face_classes1 = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 13],device=labels_predict1.device)\n",
    "        face_mask1 = torch.isin(labels_predict1, face_classes1).float().cuda()\n",
    "\n",
    "        labels_predict2 = torch.argmax(seg(img2)[0], dim=1).unsqueeze(1).long().detach()\n",
    "        face_classes2 = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 13],device=labels_predict2.device)\n",
    "        face_mask2 = torch.isin(labels_predict2, face_classes2).float().cuda()\n",
    "\n",
    "\n",
    "        cross_mask = face_mask1*face_mask2\n",
    "        img1_masked = img1[0]*cross_mask[0]\n",
    "        img2_masked = img2[0]*cross_mask[0]\n",
    "\n",
    "        denormalize = transforms.Normalize(mean=[-1, -1, -1], std=[2, 2, 2]) # 撤销之前的标准化（反标准化），使得图像像素变成原来的颜色\n",
    "        img1_masked = denormalize(img1_masked).clamp(0, 1) # 确保图像中的像素值不超出合法范围。这通常用于处理反标准化后可能出现的数值不精确性或微小的超出范围情况\n",
    "        img2_masked = denormalize(img2_masked).clamp(0, 1)\n",
    "        i+=1\n",
    "        pil_image1 = transforms.ToPILImage()(img1_masked.cpu())\n",
    "        pil_image1.save(f'output_masks/cross1/{i}.jpg')\n",
    "        #pil_image1.show()\n",
    "        pil_image2 = transforms.ToPILImage()(img2_masked.cpu())\n",
    "        pil_image2.save(f'output_masks/cross2/{i}.jpg')\n",
    "        #pil_image2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获得头发区域，其余区域为0（纯黑）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "from utils.model_utils import load_base_models\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "# 加载模型\n",
    "_, _, seg = load_base_models()\n",
    "\n",
    "# 读取图像\n",
    "color_cond = 'output.png'\n",
    "color_ref_img = Image.open(f'test_images/ref_img/{color_cond}') # PIL h:1024 w:1024\n",
    "\n",
    "# 图像转换\n",
    "color_image_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "color_cond = color_image_transform(color_ref_img).unsqueeze(0).cuda() # tensor batch:1 c:3,1024,1024\n",
    "\n",
    "# 获取分割结果\n",
    "if color_cond.shape[-1] != 1:\n",
    "    labels_predict = torch.argmax(seg(color_cond)[0], dim=1).unsqueeze(1).long().detach()\n",
    "    hair_mask = (labels_predict == 10).float()\n",
    "\n",
    "    # 将非蒙版部分设为0\n",
    "    # non_hair_mask = 1 - hair_mask\n",
    "    color_cond[0] *= hair_mask[0]\n",
    "\n",
    "    denormalize = transforms.Normalize(mean=[-1, -1, -1], std=[2, 2, 2])\n",
    "    color_cond_denormalized = denormalize(color_cond[0]).clamp(0, 1)\n",
    "    color_cond_denormalized *= hair_mask[0]\n",
    "    # color_cond = color_cond.clamp(0, 1)\n",
    "\n",
    "# 显示图像\n",
    "# pil_image = transforms.ToPILImage()(color_cond.cpu().squeeze())\n",
    "# pil_image.show()\n",
    "# pil_image.save('output_masks/color/00.jpg')\n",
    "\n",
    "# 显示图像\n",
    "pil_image = transforms.ToPILImage()(color_cond_denormalized.cpu())\n",
    "pil_image.show()\n",
    "pil_image.save('output_masks/color/118mask.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 尝试用SLIC改进颜色选取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util import img_as_float\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    " \n",
    "# load the image and convert it to a floating point data type\n",
    "\n",
    "image = img_as_float(io.imread(\"output_masks/color/5mask.jpg\"))\n",
    " \n",
    "# loop over the number of segments\n",
    "for numSegments in (100,):\n",
    "    # apply SLIC and extract (approximately) the supplied number\n",
    "    segments = slic(image, n_segments = numSegments, sigma = 2, compactness=0.2)\n",
    "    # sigma：sigma 控制在计算图像梯度时使用的高斯平滑的标准差。\n",
    "    # 较小的 sigma 值会导致对图像边缘敏感的梯度计算，从而更容易产生超像素的边缘。\n",
    "    # 较大的 sigma 值会导致对图像整体结构的平滑，从而在生成超像素时更关注整体颜色分布而不是细节。\n",
    "    # compactness：\n",
    "    # compactness 控制了超像素紧凑性的权重。较大的 compactness 会使生成的超像素更加紧凑，即更趋向于规则形状。\n",
    "    # compactness 参数的值越大，超像素的形状就越接近正方形。较小的值会导致不规则形状的超像素。\n",
    "\n",
    "    # 设置过滤超参数\n",
    "    min_nonzero_ratio_threshold = 0.2  \n",
    " \n",
    "    for segment_id in np.unique(segments):\n",
    "        # Create a mask for the current segment\n",
    "        mask = (segments == segment_id)\n",
    "\n",
    "        nonzero_ratio = np.count_nonzero(image[mask]) / np.count_nonzero(mask)\n",
    "\n",
    "        # 将大部分为黑色的色块过滤掉\n",
    "        if nonzero_ratio >= min_nonzero_ratio_threshold:\n",
    "            # Calculate area for the current segment\n",
    "            area = np.sum(mask)\n",
    "\n",
    "            # Extract the segment from the original image\n",
    "            segmented_image = image.copy()\n",
    "            segmented_image[~mask] = 0  # Set pixels outside the mask to zero\n",
    "            # Save the segmented image\n",
    "            plt.imsave(f\"output_masks/SLIC/20_10/segment2_{numSegments}_{segment_id}.png\", segmented_image)\n",
    "        \n",
    "\n",
    "    fig = plt.figure(\"Superpixels -- %d segments\" % (numSegments))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.imshow(mark_boundaries(image, segments))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.savefig(f\"superpixels_{numSegments}.png\", bbox_inches='tight', pad_inches=0.0)\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import slic, mark_boundaries, find_boundaries\n",
    "from skimage.util import img_as_float\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 加载图像并将其转换为浮点数格式\n",
    "image = img_as_float(io.imread(\"output_masks/color/00c.jpg\"))\n",
    "\n",
    "# 循环处理不同分割数\n",
    "for numSegments in (3, 5, 2):\n",
    "    # 应用 SLIC 算法并提取给定数量的分割区域\n",
    "    segments = slic(image, n_segments=numSegments, sigma=5)\n",
    "\n",
    "    # 查找分割区域之间的边界\n",
    "    segment_boundaries = find_boundaries(segments, connectivity=1, mode='outer')\n",
    "\n",
    "    # 遍历每个分割区域并单独保存\n",
    "    for segment_id in np.unique(segments):\n",
    "        # 为当前分割区域创建掩码\n",
    "        mask = (segments == segment_id)\n",
    "\n",
    "        # 排除属于边界的像素\n",
    "        mask[segment_boundaries] = False\n",
    "\n",
    "        # 从原始图像中提取分割区域\n",
    "        segmented_image = image.copy()\n",
    "        segmented_image[~mask] = 0  # 将掩码外的像素置为零\n",
    "\n",
    "        # 保存分割图像\n",
    "        plt.imsave(f\"output_masks/SLIC/segment_{numSegments}_{segment_id}.png\", segmented_image)\n",
    "\n",
    "# 显示图像\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API阿里头发分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 把图像抠图获得蒙版但是是RGB格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlopen\n",
    "from alibabacloud_imageseg20191230.client import Client\n",
    "from alibabacloud_imageseg20191230.models import SegmentHairAdvanceRequest\n",
    "from alibabacloud_tea_openapi.models import Config\n",
    "from alibabacloud_tea_util.models import RuntimeOptions\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "os.environ['ALIBABA_CLOUD_ACCESS_KEY_ID'] = '***'\n",
    "os.environ['ALIBABA_CLOUD_ACCESS_KEY_SECRET'] = '***'\n",
    "\n",
    "config = Config(\n",
    "    access_key_id=os.environ.get('ALIBABA_CLOUD_ACCESS_KEY_ID'),\n",
    "    access_key_secret=os.environ.get('ALIBABA_CLOUD_ACCESS_KEY_SECRET'),\n",
    "    endpoint='imageseg.cn-shanghai.aliyuncs.com',\n",
    "    region_id='cn-shanghai'\n",
    ")\n",
    "\n",
    "img = open(r'test_images/ref_img/5.png', 'rb')\n",
    "\n",
    "segment_hair_request = SegmentHairAdvanceRequest()\n",
    "segment_hair_request.image_urlobject = img\n",
    "runtime = RuntimeOptions()\n",
    "\n",
    "try:\n",
    "    # 初始化Client\n",
    "    client = Client(config)\n",
    "    response = client.segment_hair_advance(segment_hair_request, runtime)\n",
    "    response_data = response.body\n",
    "    image_url = response_data.data.elements[0].image_url\n",
    "    height = response_data.data.elements[0].height\n",
    "    width = response_data.data.elements[0].width\n",
    "    x = response_data.data.elements[0].x\n",
    "    y = response_data.data.elements[0].y\n",
    "    original_width = 1024\n",
    "    original_height = 1024\n",
    "    restored_image = Image.new('RGB', (original_width, original_height), color=(0, 0, 0))\n",
    "    restored_image_array = np.array(restored_image)\n",
    "\n",
    "\n",
    "    if image_url:\n",
    "        image_data = urlopen(image_url).read()\n",
    "\n",
    "        # 获取图片\n",
    "        image = Image.open(io.BytesIO(image_data))\n",
    "\n",
    "        # 调整位置大小\n",
    "\n",
    "        # 指定背景色（可以根据需求选择）\n",
    "        background_color = (0, 0, 0)  # 这里选择黑色\n",
    "\n",
    "        # 创建一个黑色背景的RGB图像\n",
    "        rgba_background = Image.new('RGBA', (original_width,original_height), background_color)\n",
    "\n",
    "        # 把背景和图像转化为numpy\n",
    "        image_array = np.array(image,dtype=np.uint8)\n",
    "        rgba_background_array = np.array(rgba_background,dtype=np.uint8)\n",
    "\n",
    "        #设置阈值a,Alpha 通道值小于某个阈值 a 时，将 RGB 通道全部设置为零\n",
    "        a = 220  # 你可以根据需要调整阈值\n",
    "        # 将 Alpha 通道小于阈值的区域的 RGB 通道设置为零\n",
    "        alpha_channel = image_array[:, :, 3]\n",
    "        image_array[alpha_channel < a, :3] = 0\n",
    "        image_array[alpha_channel >= a, :3] = 255\n",
    "\n",
    "        # 依据y,x,heigth,width得出图像在背景中的位置\n",
    "        rgba_background_array[y:y + height, x:x + width] = image_array \n",
    "\n",
    "        image_pil = Image.fromarray(rgba_background_array, 'RGBA')\n",
    "\n",
    "        result_image = Image.alpha_composite(Image.new('RGBA', rgba_background.size, (0, 0, 0, 0)), image_pil)\n",
    "\n",
    "        result_image = result_image.convert('RGB')\n",
    "        result_image.save(\"output_rgb_image.png\")\n",
    "\n",
    "        # 现在你可以将 'image_array' 用作 NumPy 变量\n",
    "        print('图像形状:', result_image.shape)\n",
    "\n",
    "        with open('output_image.png', 'wb') as f:\n",
    "            f.write(image_data)\n",
    "        print('图像保存到本地文件: output_image.png')\n",
    "\n",
    "    else:\n",
    "        print('响应中未找到图像URL。')\n",
    "\n",
    "    # 获取整体结果\n",
    "    print(response.body)\n",
    "except Exception as error:\n",
    "    # 获取整体报错信息\n",
    "    print(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlopen\n",
    "from alibabacloud_imageseg20191230.client import Client\n",
    "from alibabacloud_imageseg20191230.models import SegmentHairAdvanceRequest\n",
    "from alibabacloud_tea_openapi.models import Config\n",
    "from alibabacloud_tea_util.models import RuntimeOptions\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "os.environ['ALIBABA_CLOUD_ACCESS_KEY_ID'] = '***'\n",
    "os.environ['ALIBABA_CLOUD_ACCESS_KEY_SECRET'] = '***'\n",
    "\n",
    "config = Config(\n",
    "access_key_id=os.environ.get('ALIBABA_CLOUD_ACCESS_KEY_ID'),\n",
    "access_key_secret=os.environ.get('ALIBABA_CLOUD_ACCESS_KEY_SECRET'),\n",
    "endpoint='imageseg.cn-shanghai.aliyuncs.com',\n",
    "region_id='cn-shanghai'\n",
    ")\n",
    "\n",
    "# 定义图像文件夹路径和输出文件夹路径\n",
    "input_folder = 'test_images/loukonghair/'\n",
    "output_folder = 'output_images/'\n",
    "\n",
    "# 确保输出文件夹存在\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 遍历图像文件夹\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".png\") or filename.endswith(\".jpg\"):\n",
    "        # 读取图像\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "        img = open(img_path, 'rb')\n",
    "\n",
    "        segment_hair_request = SegmentHairAdvanceRequest()\n",
    "        segment_hair_request.image_urlobject = img\n",
    "        runtime = RuntimeOptions()\n",
    "\n",
    "        # 初始化Client\n",
    "        client = Client(config)\n",
    "        response = client.segment_hair_advance(segment_hair_request, runtime)\n",
    "        response_data = response.body\n",
    "        image_url = response_data.data.elements[0].image_url\n",
    "        height = response_data.data.elements[0].height\n",
    "        width = response_data.data.elements[0].width\n",
    "        x = response_data.data.elements[0].x\n",
    "        y = response_data.data.elements[0].y\n",
    "        original_width = 1024\n",
    "        original_height = 1024\n",
    "\n",
    "    if image_url:\n",
    "        image_data = urlopen(image_url).read()\n",
    "        with open('output_image.png', 'wb') as f:\n",
    "            f.write(image_data)\n",
    "        print('Image saved to local file: output_image.png')\n",
    "\n",
    "        image = Image.open(io.BytesIO(image_data))\n",
    "\n",
    "        # 指定背景色（可以根据需求选择）\n",
    "        background_color = (127, 127, 127)  # 这里选择黑色\n",
    "\n",
    "        # 创建一个黑色背景的RGB图像\n",
    "        rgba_background = Image.new('RGBA', (original_width,original_height), background_color)\n",
    "\n",
    "        # 把背景和图像转化为numpy\n",
    "        image_array = np.array(image,dtype=np.uint8)\n",
    "        rgba_background_array = np.array(rgba_background,dtype=np.uint8)\n",
    "\n",
    "        #设置阈值a,Alpha 通道值小于某个阈值 a 时，将 RGB 通道全部设置为零\n",
    "        a = 255  # 你可以根据需要调整阈值\n",
    "        # 将 Alpha 通道小于阈值的区域的 RGB 通道设置为零\n",
    "        alpha_channel = image_array[:, :, 3]\n",
    "        image_array[alpha_channel < a, :3] = 127\n",
    "        #image_array[alpha_channel >= a, :3] = 255\n",
    "\n",
    "        # 依据y,x,heigth,width得出图像在背景中的位置\n",
    "        rgba_background_array[y:y + height, x:x + width] = image_array \n",
    "\n",
    "        image_pil = Image.fromarray(rgba_background_array, 'RGBA')\n",
    "\n",
    "        result_image = Image.alpha_composite(Image.new('RGBA', rgba_background.size, (127, 127, 127, 0)), image_pil)\n",
    "\n",
    "        result_image = np.array(result_image)\n",
    "        #result_image = result_image[:, :, 0]\n",
    "        # result_image_path = os.path.join(output_folder, filename.replace(\".\", \"_segmented.\"))\n",
    "        # result_image = Image.fromarray(result_image)\n",
    "        # result_image.save(result_image_path)\n",
    "        result_image_pil = Image.fromarray(result_image.astype('uint8'))\n",
    "\n",
    "        # Convert to RGB mode if needed\n",
    "        result_image_pil = result_image_pil.convert('RGB')\n",
    "        result_image_path = os.path.join(output_folder, filename.replace(\".\", \"_segmented.\"))\n",
    "        result_image_pil.save(result_image_path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HairCLIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
